{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from collections import namedtuple, deque\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward', 'is_done'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Модель Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class QNet(nn.Module):\n",
    "#    # слои модели   \n",
    "#    def __init__(self, n_state, n_action, n_hidden):\n",
    "#        super().__init__()\n",
    "#\n",
    "#        self.hidden = nn.Linear(n_state, n_hidden)\n",
    "#        self.output = nn.Linear(n_hidden, n_action)\n",
    "#\n",
    "#    # способ обучения модели\n",
    "#    def forward(self, s, a):\n",
    "#        outs = torch.cat((s, a), dim=-1)\n",
    "#        outs = self.hidden(outs)\n",
    "#        outs = F.relu(outs)\n",
    "#        outs = self.output(outs)\n",
    "#        return outs\n",
    "    \n",
    "\n",
    "class QNet(nn.Module):\n",
    "    def __init__(self, n_action):\n",
    "        super(QNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, stride=1)\n",
    "        self.fc = torch.nn.Linear(7 * 7 * 64 + 1, 512)\n",
    "        self.out = torch.nn.Linear(512, n_action)\n",
    "\n",
    "    def forward(self, s, a):\n",
    "        #outs = torch.cat((s, a), dim=-1) # непонятно как оно должно выглядеть\n",
    "        outs = F.relu(self.conv1(s))\n",
    "        outs = F.relu(self.conv2(outs))\n",
    "        outs = F.relu(self.conv3(outs))\n",
    "        outs = outs.view(outs.size(0), -1)\n",
    "        outs = outs.squeeze(dim=0)\n",
    "        outs = torch.concat((outs, a), dim=0)#наверное сюда\n",
    "        outs = F.relu(self.fc(outs))\n",
    "        output = self.out(outs)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Модель Политики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class PolicyNet(nn.Module):\n",
    "#    # слои модели\n",
    "#    def __init__(self, n_state, n_hidden):\n",
    "#        super().__init__()\n",
    "#\n",
    "#        self.hidden = nn.Linear(n_state, n_hidden)\n",
    "#        self.output = nn.Linear(n_hidden, 1)\n",
    "#\n",
    "#    # способ обучения модели\n",
    "#    def forward(self, s):\n",
    "#        outs = self.hidden(s)\n",
    "#        outs = F.relu(outs)\n",
    "#        outs = self.output(outs)\n",
    "#        outs = torch.tanh(outs)\n",
    "#        return outs\n",
    "    \n",
    "class PolicyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PolicyNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, stride=1)\n",
    "        self.fc = torch.nn.Linear(7 * 7 * 64, 256)\n",
    "        self.out = torch.nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, s):\n",
    "        outs = F.relu(self.conv1(s))\n",
    "        outs = F.relu(self.conv2(outs))\n",
    "        outs = F.relu(self.conv3(outs))\n",
    "        outs = outs.view(outs.size(0), -1)\n",
    "        outs = F.relu(self.fc(outs))\n",
    "        output = self.out(outs)\n",
    "        return output  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ Q_{\\phi}(s, \\mu_{\\theta}(s)) = r_t + \\gamma (1 - d_t) Q_{{\\phi}^{\\prime}}(s_{t+1},\\mu_{\\theta^{\\prime}}(s_{t+1})) $\n",
    "\n",
    "$ \\phi^{\\prime} = \\tau \\phi + (1-\\tau) \\phi^{\\prime} $\n",
    "\n",
    "$ \\theta^{\\prime} = \\tau \\theta + (1-\\tau) \\theta^{\\prime} $\n",
    "\n",
    "В итоге алгоритм имеет вид :\n",
    "\n",
    "- Собираем кортежи $ (s_t, a_t, r_t, s_{t+1}, d_t) $\n",
    "- Оптимизируем $ \\phi $ чтобы свести к минимуму $L$ in (4)\n",
    "- Оптимизируем $ \\theta $ чтобы свести к минимуму $Q_{\\phi}(s, \\mu_{\\theta}(s))$\n",
    "- Обновиляем целевые параметры следующим образом\n",
    "    - $ \\phi^{\\prime} = \\tau \\phi + (1-\\tau) \\phi^{\\prime} $\n",
    "    - $ \\theta^{\\prime} = \\tau \\theta + (1-\\tau) \\theta^{\\prime} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_next(q_current_agent, q_next_agent, \n",
    "               mu_current_agent, mu_next_agent,\n",
    "               tau = 0.002):\n",
    "    for q_current, q_next in zip(q_current_agent.parameters(), q_next_agent.parameters()):\n",
    "        q_next.data = tau * q_current.data + (1.0 - tau) * q_next.data\n",
    "    for mu_current, mu_next in zip(mu_current_agent.parameters(), mu_next_agent.parameters()):\n",
    "        mu_next.data = tau * mu_current.data + (1.0 - tau) * mu_next.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Функция политики выбора действия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция шума\n",
    "class OrnsteinUhlenbeckActionNoise:\n",
    "    def __init__(self, mu, sigma, theta=.15, dt=1e-2, x0=None):\n",
    "        self.theta = theta\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.dt = dt\n",
    "        self.x0 = x0\n",
    "        self.reset()\n",
    "\n",
    "    def __call__(self):\n",
    "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + self.sigma * np.sqrt(self.dt) * np.random.normal(size=self.mu.shape)\n",
    "        self.x_prev = x\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        self.x_prev = self.x0 if self.x0 is not None else np.zeros_like(self.mu)\n",
    "\n",
    "ou_action_noise = OrnsteinUhlenbeckActionNoise(mu=np.zeros(1), sigma=np.ones(1) * 0.05)\n",
    "\n",
    "# Получить у модели Исполнителя действие максимальной вероятности без обучния\n",
    "def policy(policy_agent, state, n_action):\n",
    "    with torch.no_grad():\n",
    "        state = torch.tensor(state, device=DEVICE)\n",
    "        action_det = policy_agent(state)\n",
    "        action_det = action_det.squeeze(dim=1)\n",
    "        noise = ou_action_noise()\n",
    "        a = action_det.cpu().numpy() + noise\n",
    "        a = np.clip(a, 0., float(n_action) - 0.00001)\n",
    "        a = int(a.item())\n",
    "        \n",
    "        action = [0,0,0]\n",
    "        if a == 0:\n",
    "            action[0] = -1\n",
    "        elif a == 1:\n",
    "            action[0] = 1\n",
    "        elif a == 2:\n",
    "            action[1] = 1\n",
    "        else:\n",
    "            action[2] = 1\n",
    "        return action, a    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# трансфомация изображения под заданные размер (в квадрат)\n",
    "def transform(image_size):\n",
    "    return T.Compose( [ T.ToPILImage(),\n",
    "                        T.Resize((image_size, image_size), interpolation=Image.BICUBIC),\n",
    "                        T.ToTensor(),\n",
    "                        ])\n",
    "\n",
    "# каналы изображения перемещаем перед размерами\n",
    "def chanal_to_front(obs,image_size):\n",
    "    state = obs.transpose((2, 0, 1))\n",
    "    state = torch.tensor(state, dtype=torch.float, device=DEVICE)\n",
    "    state = transform(image_size)(state).unsqueeze(0)\n",
    "    return state.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Функция обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learning(env, \n",
    "               q_current_agent, q_next_agent, \n",
    "               mu_current_agent, mu_next_agent, \n",
    "               opt_q_agent, opt_mu_agent, \n",
    "               memory, batch_size, \n",
    "               n_episodes, n_action, total_reward_episode, gamma):\n",
    "\n",
    "\n",
    "    # размер скрина (скрин квадратный)\n",
    "    image_size = 84 #env.observation_space.shape[0]\n",
    "\n",
    "    # для каждой эпохи\n",
    "    for n in tqdm(range(n_episodes)):\n",
    "\n",
    "        # сбросить среду\n",
    "        state,_ = env.reset()\n",
    "        # подготовка изображения для передачи на свертку\n",
    "        state = chanal_to_front(state, image_size)\n",
    "        \n",
    "        is_done = False\n",
    "        # запуск среды\n",
    "        while not is_done:\n",
    "\n",
    "\n",
    "\n",
    "            # получить действие от Испольнителя (без обученния)\n",
    "            action, a_to_mem  = policy(mu_current_agent, state, n_action)\n",
    "            # запустить среду с этим действием и получить ее результирующее состояние\n",
    "            next_state, reward, is_done, is_break, _ = env.step(action)\n",
    "            \n",
    "            total_reward_episode[n] += reward\n",
    "            is_done = is_done or is_break\n",
    "\n",
    "            # подготовка изображения для передачи на свертку\n",
    "            next_state = chanal_to_front(next_state, image_size)\n",
    "\n",
    "            # сохранить результаты в буфер\n",
    "            m_action = torch.tensor([a_to_mem], device=DEVICE, dtype=torch.float)\n",
    "            m_state = torch.tensor(state, device=DEVICE, dtype=torch.float)\n",
    "            m_reward = torch.tensor([reward], device=DEVICE, dtype=torch.float)\n",
    "            m_next_state = torch.tensor(next_state, device=DEVICE, dtype=torch.float)\n",
    "            m_is_done = torch.tensor([is_done], device=DEVICE, dtype=torch.float)\n",
    "            memory.append(Transition(m_state, m_action, m_reward, m_next_state, m_is_done))\n",
    "            state = next_state\n",
    "\n",
    "            if len(memory) < batch_size:\n",
    "                continue\n",
    "\n",
    "            # получаем случайный батч из буффера\n",
    "            batch = random.sample(memory, batch_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            q_current_batch = []\n",
    "            q_next_batch = []\n",
    "            for mb_state, mb_action, mb_reward, mb_next_state, mb_is_done in batch:\n",
    "                # Обучение модели Q\n",
    "                # обучить модель на списке стартового состояния  и действия\n",
    "                # Получим текущую Q(s,a)\n",
    "                q_current = q_current_agent(mb_state, mb_action)\n",
    "                q_current_batch.append(q_current.tolist())\n",
    "                # Получим mu от следующего состояния\n",
    "                mu_next = mu_next_agent(mb_state)\n",
    "                mu_next = mu_next.squeeze(dim=1)\n",
    "                # Получим от следующего состояния Q1(s1,mu)\n",
    "                q_next = q_next_agent(mb_next_state, mu_next)\n",
    "                q_next = mb_reward + gamma * (1. - float(mb_is_done)) * q_next\n",
    "                q_next_batch.append(q_next.tolist())\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "            q_current_batch = torch.tensor(q_current_batch, device=DEVICE, dtype=torch.float, requires_grad=True)\n",
    "            q_next_batch = torch.tensor(q_next_batch, device=DEVICE, dtype=torch.float)\n",
    "            # обнулить градиенты\n",
    "            opt_q_agent.zero_grad()\n",
    "            # считаем лосс \n",
    "            q_loss = F.mse_loss(q_current_batch, q_next_batch, reduction=\"none\")\n",
    "            # считаем сумму потерь\n",
    "            loss = q_loss.sum()\n",
    "            # делаем шаг лосс в обратном направлении\n",
    "            loss.backward()\n",
    "            # делаем шаг оптимизатора\n",
    "            opt_q_agent.step()\n",
    "\n",
    "\n",
    "            for p in q_current_agent.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "            q_current_max_batch = []\n",
    "            for mb_state, mb_action, mb_reward, mb_next_state, mb_is_done in batch:\n",
    "                # Обучение модели Mu\n",
    "                # обучить модель на списке стартового состояния\n",
    "                mu_current = mu_current_agent(mb_state)\n",
    "                mu_current = mu_current.squeeze(dim=1)\n",
    "                q_current_max = q_current_agent(mb_state, mu_current)\n",
    "                q_current_max_batch.append(q_current_max.tolist())\n",
    "\n",
    "            q_current_max_batch = torch.tensor(q_current_max_batch, device=DEVICE, dtype=torch.float, requires_grad=True)\n",
    "            # обнулить градиенты\n",
    "            opt_mu_agent.zero_grad()\n",
    "            # считаем лосс \n",
    "            act_loss = (-q_current_max_batch).sum()\n",
    "            # делаем шаг лосс в обратном направлении\n",
    "            act_loss.backward()\n",
    "            # делаем шаг оптимизатора\n",
    "            opt_mu_agent.step()\n",
    "\n",
    "            for p in q_current_agent.parameters():\n",
    "                p.requires_grad = True\n",
    "\n",
    "            update_next(q_current_agent, q_next_agent,  mu_current_agent, mu_next_agent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Среда обучения "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CarRacing-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 96, 3)\n",
      "Box([-1.  0.  0.], 1.0, (3,), float32)\n"
     ]
    }
   ],
   "source": [
    "state_shape = env.observation_space.shape\n",
    "n_action = env.action_space\n",
    "print(state_shape)\n",
    "print(n_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Создание моделей с заданными параметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# параемры моделей\n",
    "# количество входящих парамеров\n",
    "n_state = env.observation_space.shape[0]\n",
    "# количество выходящих парамеров исполинтельной сети\n",
    "n_action = 4\n",
    "# скорость обучения\n",
    "LR = 0.0005\n",
    "\n",
    "# 1. Задать модель - nn.Module\n",
    "q_current_agent = QNet(n_action).to(DEVICE)\n",
    "q_next_agent = QNet(n_action).to(DEVICE)\n",
    "q_next_agent.requires_grad_(False)\n",
    "\n",
    "mu_current_agent = PolicyNet().to(DEVICE)\n",
    "mu_next_agent = PolicyNet().to(DEVICE)\n",
    "mu_next_agent.requires_grad_(False)\n",
    "\n",
    "# 2. Задать оптимизатор - torch.optim.NAME_OF_OPTIM\n",
    "opt_q_agent = torch.optim.Adam(q_current_agent.parameters(), lr=LR)\n",
    "opt_mu_agent = torch.optim.Adam(mu_current_agent.parameters(), lr=LR)\n",
    "\n",
    "# 3. Задать буфер состояний действий наград будущих состояний и конца моделирования (Transition)\n",
    "memory = deque(maxlen=100000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Запуск обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 12/500 [1:02:34<42:24:23, 312.84s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[270], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# запуск функции обучения\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mq_learning\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m           \u001b[49m\u001b[43mq_current_agent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_next_agent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmu_current_agent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu_next_agent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m           \u001b[49m\u001b[43mopt_q_agent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_mu_agent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m           \u001b[49m\u001b[43mn_episodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_reward_episode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[266], line 61\u001b[0m, in \u001b[0;36mq_learning\u001b[1;34m(env, q_current_agent, q_next_agent, mu_current_agent, mu_next_agent, opt_q_agent, opt_mu_agent, memory, batch_size, n_episodes, n_action, total_reward_episode, gamma)\u001b[0m\n\u001b[0;32m     56\u001b[0m q_next_batch \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mb_state, mb_action, mb_reward, mb_next_state, mb_is_done \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;66;03m# Обучение модели Q\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# обучить модель на списке стартового состояния  и действия\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# Получим текущую Q(s,a)\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m     q_current \u001b[38;5;241m=\u001b[39m \u001b[43mq_current_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmb_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmb_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m     q_current_batch\u001b[38;5;241m.\u001b[39mappend(q_current\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m# Получим mu от следующего состояния\u001b[39;00m\n",
      "File \u001b[1;32mr:\\Scool\\Anaconda\\envs\\rl_conda_311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mr:\\Scool\\Anaconda\\envs\\rl_conda_311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[261], line 30\u001b[0m, in \u001b[0;36mQNet.forward\u001b[1;34m(self, s, a)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, a):\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m#outs = torch.cat((s, a), dim=-1) # непонятно как оно должно выглядеть\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     outs \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(s))\n\u001b[1;32m---> 30\u001b[0m     outs \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mouts\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     31\u001b[0m     outs \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(outs))\n\u001b[0;32m     32\u001b[0m     outs \u001b[38;5;241m=\u001b[39m outs\u001b[38;5;241m.\u001b[39mview(outs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mr:\\Scool\\Anaconda\\envs\\rl_conda_311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mr:\\Scool\\Anaconda\\envs\\rl_conda_311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mr:\\Scool\\Anaconda\\envs\\rl_conda_311\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mr:\\Scool\\Anaconda\\envs\\rl_conda_311\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# общее количество эпох\n",
    "n_episodes = 500\n",
    "# коэффициент обесценивания \n",
    "gamma = 0.99\n",
    "# общая награда в каждом эпизоде\n",
    "total_reward_episode = np.zeros(n_episodes)\n",
    "# размер батча\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "# запуск функции обучения\n",
    "q_learning(env, \n",
    "           q_current_agent, q_next_agent, \n",
    "           mu_current_agent, mu_next_agent, \n",
    "           opt_q_agent, opt_mu_agent, \n",
    "           memory, batch_size, \n",
    "           n_episodes, n_action, total_reward_episode, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(total_reward_episode)\n",
    "plt.title('Зависимость вознаграждения в эпизоде от времени')\n",
    "plt.xlabel('Эпизод')\n",
    "plt.ylabel('Полное вознаграждение')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_conda_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
