{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import torch\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import deque\n",
    "from collections import namedtuple\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Модель Исполнитель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# слои модели\n",
    "# способ обусения молеи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Модель Критик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# слои модели\n",
    "# способ обусения молеи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Функция политики выбора действия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получить у модели Исполнителя действия максимальной вероятности без обучния\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Функция обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# для каждой эпохи\n",
    "\n",
    "    # сбросить среду\n",
    "    # создать создать списки стартового состояния, действий и наград за действия для каждого шага\n",
    "    # \n",
    "\n",
    "    # запуск среды\n",
    "        # получить действие от Испольнителя (без обученния)\n",
    "        # запустить среду с этим действием и получить ее результирующее состояние\n",
    "        # сохранить в списки стартового состояния, действие и награду за действие\n",
    "\n",
    "\n",
    "    # из списка наград за отдельное действие получить список сумм нагдад за все действия до текущего в списке\n",
    "    # список Полных наград для кажного состояния среды\n",
    "\n",
    "    # Обучение модели Критика\n",
    "    # обучить модель на списке стартового состояния\n",
    "    # обнулить градиенты\n",
    "    # считаем лосс из оценок Критика () и списка полных вознаграждений\n",
    "    # считаем сумму потерь\n",
    "    # делаем шаг лосс в обратном направлении\n",
    "    # делаем шаг оптимизатора\n",
    "\n",
    "    # получение ценности состояний из оценок Критика и списка полных вознаграждений (без обучения)\n",
    "\n",
    "    # Обучение модели Исполнителя\n",
    "    # обучить модель на списке стартового состояния\n",
    "    # обнулить градиенты\n",
    "    # считаем лосс из оценок Исполнителя (действия) и списка осуществленных действий (логарифм вероятностей изменения состояний)\n",
    "    # считаем сумму произведений отрицательных логорифмов потери на ценность состояний\n",
    "    # делаем шаг лосс в обратном направлении\n",
    "    # делаем шаг оптимизатора\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Создание моделей с заданными параметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# параемры моделей\n",
    "# количество входящих парамеров\n",
    "# количество выходящих парамеров исполинтельной сети\n",
    "# количество скрытых нейронов\n",
    "# скорость обучения\n",
    "# 1. Задать модель - nn.Module\n",
    "# 2. Задать функцию потерь - nn.NAME_OF_FUNC\n",
    "# 3. Задать оптимизатор - torch.optim.NAME_OF_OPTIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Среда обучения "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Запуск обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# общее количество эпох\n",
    "# коэффициент обесценивания \n",
    "# общая награда в каждом эпизоде\n",
    "# запуск функции обучения\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_conda_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
